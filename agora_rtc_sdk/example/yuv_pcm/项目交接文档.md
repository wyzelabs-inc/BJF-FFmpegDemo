# Agoraå®æ—¶è¯­éŸ³å¯¹è¯ç³»ç»Ÿ - æŠ€æœ¯äº¤æ¥æ–‡æ¡£

## 1. ç³»ç»ŸåŠŸèƒ½å®ç°

### æ ¸å¿ƒåŠŸèƒ½
æœ¬ç³»ç»Ÿå®ç°äº†ä¸€ä¸ª**å®æ—¶è¯­éŸ³å¯¹è¯AIåŠ©æ‰‹**ï¼Œå…·ä½“åŠŸèƒ½åŒ…æ‹¬ï¼š

1. **å®æ—¶è¯­éŸ³ç›‘å¬**: é€šè¿‡Agora RTC SDKæ¥æ”¶éŸ³é¢‘æµ
2. **è¯­éŸ³æ´»åŠ¨æ£€æµ‹(VAD)**: è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·ä½•æ—¶å¼€å§‹å’Œç»“æŸè¯´è¯
3. **è¯­éŸ³è½¬æ–‡å­—(ASR)**: å°†ç”¨æˆ·è¯­éŸ³è½¬æ¢ä¸ºæ–‡å­—
4. **AIå¯¹è¯**: è°ƒç”¨GPT APIç”Ÿæˆæ™ºèƒ½å›å¤
5. **çŠ¶æ€ç®¡ç†**: ç®¡ç†æ•´ä¸ªå¯¹è¯æµç¨‹çš„çŠ¶æ€åˆ‡æ¢

### å®Œæ•´å·¥ä½œæµç¨‹
```
ç”¨æˆ·è¯´è¯ â†’ AgoraéŸ³é¢‘æµ â†’ VADæ£€æµ‹è¯­éŸ³å¼€å§‹/ç»“æŸ â†’ æ”¶é›†è¯­éŸ³ç‰‡æ®µ â†’ ASRè¯†åˆ« â†’ GPTç”Ÿæˆå›å¤ â†’ å›åˆ°ç›‘å¬çŠ¶æ€
```

## 2. C++ä¸Pythonäº¤äº’æœºåˆ¶

### 2.1 äº¤äº’æ¶æ„
- **C++ç«¯**: è´Ÿè´£AgoraéŸ³é¢‘æµæ¥æ”¶å’Œå®æ—¶å¤„ç†
- **Pythonç«¯**: è´Ÿè´£AIæ¨¡å‹æ¨ç†å’Œä¸šåŠ¡é€»è¾‘
- **äº¤äº’æ–¹å¼**: C++é€šè¿‡Python C APIç›´æ¥è°ƒç”¨Pythonå‡½æ•°

### 2.2 å…³é”®äº¤äº’å‡½æ•°

#### C++è°ƒç”¨Pythonçš„æ¡¥æ¥å‡½æ•°ï¼š

1. **`bridge_initialize()`** - ç³»ç»Ÿåˆå§‹åŒ–
   ```cpp
   // C++è°ƒç”¨
   PyObject* result = PyObject_CallFunction(bridge_initialize_func, "ssffi",
       asr_model_dir, vad_model_dir, vad_threshold, vad_threshold_low, sample_rate);
   ```

2. **`bridge_process_audio()`** - éŸ³é¢‘æ•°æ®å¤„ç†
   ```cpp
   // C++è°ƒç”¨
   PyObject* result = PyObject_CallFunction(bridge_process_audio_func, "iiiii",
       (long)audioFrame.buffer,     // éŸ³é¢‘æ•°æ®æŒ‡é’ˆ
       dataSize,                    // æ•°æ®å­—èŠ‚å¤§å°
       audioFrame.samplesPerChannel, // æ¯å£°é“æ ·æœ¬æ•°
       audioFrame.channels,         // å£°é“æ•°
       audioFrame.samplesPerSec);   // é‡‡æ ·ç‡
   ```

3. **`bridge_get_statistics()`** - è·å–ç»Ÿè®¡ä¿¡æ¯
4. **`bridge_shutdown()`** - ç³»ç»Ÿå…³é—­

### 2.3 æ•°æ®ä¼ é€’å’Œè½¬æ¢

#### çº¿ç¨‹å®‰å…¨ä¸GILç®¡ç†
ç”±äºAgoraçš„éŸ³é¢‘å›è°ƒå‡½æ•°åœ¨ç‹¬ç«‹çš„C++çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œç›´æ¥è°ƒç”¨python C APIä¼šå› å…¨å±€è§£é‡Šå™¨é”GILé—®é¢˜å¯¼è‡´ç¨‹åºå´©æºƒ(æ®µé”™è¯¯)

**è§£å†³æ–¹æ¡ˆ**
1. **åˆå§‹åŒ–**:åœ¨C++ä¸»çº¿ç¨‹åˆå§‹åŒ–pythonåï¼Œè°ƒç”¨'PyEval_SaveThread()'é‡Šæ”¾GILï¼Œå…è®¸å…¶ä»–çº¿ç¨‹è·å–ã€‚
2. **éŸ³é¢‘å¤„ç†**:åœ¨C++éŸ³é¢‘å›è°ƒçº¿ç¨‹ä¸­ï¼Œè°ƒç”¨pythonå‡½æ•°(å¦‚'bridge_process_audio')å‰ï¼Œå¿…é¡»ä½¿ç”¨'PyGILState_Ensure()'è·å–GIL;è°ƒç”¨ç»“æŸåï¼Œä½¿ç”¨'PyGILState_Release()'é‡Šæ”¾GILã€‚
3. **å…³é—­**: åœ¨ä¸»çº¿ç¨‹è°ƒç”¨ `Py_FinalizeEx()` å…³é—­è§£é‡Šå™¨å‰ï¼Œå¿…é¡»é‡æ–°è·å–GILã€‚å› ä¸ºåœ¨åˆå§‹åŒ–é˜¶æ®µè°ƒç”¨äº† `PyEval_SaveThread()`ï¼Œä¸»çº¿ç¨‹å·²ç»é‡Šæ”¾äº†GILã€‚å› æ­¤ï¼Œæ­£ç¡®çš„å…³é—­é¡ºåºæ˜¯å…ˆè°ƒç”¨ `PyGILState_Ensure()`ï¼Œå†è°ƒç”¨ `Py_FinalizeEx()`ï¼Œè¿™èƒ½æœ‰æ•ˆé¿å…ç¨‹åºé€€å‡ºæ—¶å‘ç”Ÿæ®µé”™è¯¯ã€‚

#### éŸ³é¢‘æ•°æ®è½¬æ¢æµç¨‹ï¼š
```
Agora AudioFrame (C++) â†’ Pythonå¤„ç†
    â†“
1. void* buffer (PCM int16æ ¼å¼)
    â†“
2. ctypes.string_at(audio_data_ptr, data_size)
    â†“
3. np.frombuffer(audio_data, dtype=np.int16)
    â†“
4. å¤šå£°é“å¤„ç†: audio_array[::channels] (å–å·¦å£°é“)
    â†“
5. æ ¼å¼è½¬æ¢: audio_array.astype(np.float32) / 32768.0
    â†“
6. æœ€ç»ˆæ ¼å¼: numpy float32æ•°ç»„ï¼ŒèŒƒå›´[-1.0, 1.0]
```

#### å…³é”®æ•°æ®ç»“æ„ï¼š
- **è¾“å…¥**: Agora AudioFrame (16kHz, 16bit PCM)
- **ä¼ é€’**: å†…å­˜æŒ‡é’ˆ + æ•°æ®å¤§å°
- **å¤„ç†**: numpy float32æ•°ç»„
- **è¾“å‡º**: JSONæ ¼å¼ç»Ÿè®¡ä¿¡æ¯

## 3. çº¿ç¨‹å’Œé˜Ÿåˆ—æ¶æ„

### 3.1 çº¿ç¨‹ç»“æ„
ç³»ç»Ÿé‡‡ç”¨**2çº¿ç¨‹æ¶æ„**ï¼š

1. **ä¸»çº¿ç¨‹ (C++)**:
   - è¿è¡ŒAgora RTC SDK
   - æ¥æ”¶å®æ—¶éŸ³é¢‘æµ
   - è°ƒç”¨Pythonå¤„ç†å‡½æ•°
   - è´Ÿè´£éŸ³é¢‘æ•°æ®çš„å®æ—¶ä¼ é€’

2. **Pythonå¼‚æ­¥çº¿ç¨‹**:
   - å¤„ç†ASRè¯†åˆ« (å½“æ£€æµ‹åˆ°å®Œæ•´è¯­éŸ³ç‰‡æ®µæ—¶å¯åŠ¨)
   - è°ƒç”¨GPT APIç”Ÿæˆå›å¤
   - æ‰§è¡Œ`_process_conversation()`å‡½æ•°

### 3.2 é˜Ÿåˆ—ç³»ç»Ÿ
ç³»ç»Ÿä½¿ç”¨**3ä¸ªä¸»è¦ç¼“å†²åŒº**ï¼š

1. **VADéŸ³é¢‘ç¼“å†²åŒº** (`SileroVAD.audio_buffer`):
   - **ä½œç”¨**: å­˜å‚¨ç”¨äºVADåˆ†æçš„éŸ³é¢‘å¸§
   - **å¤§å°**: 512æ ·æœ¬ (32ms@16kHz)
   - **å¤„ç†**: æ»‘åŠ¨çª—å£ï¼Œå¤„ç†å®Œå³ä¸¢å¼ƒ,ä»…ç”¨äºVADæ¨¡å‹å†…éƒ¨

2. **è¯­éŸ³æ”¶é›†ç¼“å†²åŒº** (`AgoraConversationSystem.speech_buffer`)+å‰ç½®ç¼“å†²åŒº(`pre_buffer`):
   - **ä½œç”¨**: è§£å†³è¯­éŸ³å¼€å¤´æ•°æ®ä¸¢å¤±çš„å…³é”®è®¾è®¡ã€‚åœ¨ç³»ç»Ÿç¡®è®¤è¯­éŸ³å¼€å§‹å‰ï¼ŒæŒç»­ç¼“å­˜æœ€è¿‘çš„éŸ³é¢‘æ•°æ®
   - **å¤§å°**: åŠ¨æ€å¢é•¿ï¼Œè¯­éŸ³ç»“æŸæ—¶å¤„ç†
   - **å¤„ç†**: å½“VADçŠ¶æ€æœºç¡®è®¤è¯­éŸ³å¼€å§‹æ—¶ï¼Œæ­¤ç¼“å†²åŒºå†…çš„å†…å®¹ä¼šé¦–å…ˆè¢«å¤åˆ¶åˆ°`speech_buffer`ä¸­ï¼Œç¡®ä¿è¯­éŸ³å®Œæ•´æ€§

#### 3.2.1 éŸ³é¢‘å—æµå‘å›¾
1. ä¸‹å›¾è¯´æ˜`audio_chunk`å¦‚ä½•æ ¹æ®ç³»ç»ŸçŠ¶æ€è¢«é€å…¥ä¸åŒçš„ç¼“å†²åŒºï¼š
```
+---------------------+
|  C++ æ¥æ”¶éŸ³é¢‘å¸§     |
+---------------------+
           |
           v
+---------------------+
| Python æ¥æ”¶ audio_chunk |
+---------------------+
           |
           v
+--------------------------------+
| process_audio_chunk()          |
|  (if state != LISTENING: return) |
+--------------------------------+
           |
           v
+--------------------------------+      +--------------------------+
| VAD.process_audio(audio_chunk) |----->| VADå†…éƒ¨ç¼“å†²åŒº (ç”¨äºåˆ†æ) |
+--------------------------------+      +--------------------------+
           |
           v
+--------------------------------+
| is_collecting_speech?          |
|      |                 |       |
|     YES                NO      |
|      |                 |       |
|      v                 v       |
| speech_buffer     pre_buffer   |
+--------------------------------+
           |
           v
+--------------------------------+
| VADçŠ¶æ€æœºåˆ¤æ–­ speech_start     |
|                                |
| if speech_start:               |
|   speech_buffer = pre_buffer   |
|   is_collecting_speech = True  |
+--------------------------------+
```
2. ä¸‹å›¾è¯´æ˜ä»éŸ³é¢‘è¾“å…¥åˆ°ASRå¤„ç†çš„å®Œæ•´æµç¨‹:
```
+---------------------+
|   æ¥æ”¶ audio_chunk   |
+---------------------+
           |
           v
+---------------------+
|  VAD çŠ¶æ€æœºåˆ†æ      |
| (has_voice?)        |
+---------------------+
           |
           | speech_start?
           | (è¿ç»­è¯­éŸ³å— > 7)
           v
+--------------------------------+
| ğŸ¤ å¼€å§‹æ”¶é›†è¯­éŸ³                  |
| speech_buffer = pre_buffer     |
| is_collecting_speech = True    |
+--------------------------------+
           |
           v
+--------------------------------+
| æŒç»­å°† audio_chunk             |
| æ·»åŠ åˆ° speech_buffer           |
+--------------------------------+
           |
           | speech_end?
           | (è¿ç»­é™éŸ³å— > 15)
           v
+--------------------------------+
| ğŸ”‡ è¯­éŸ³ç»“æŸ                     |
| is_collecting_speech = False   |
+--------------------------------+
           |
           | è¯­éŸ³æ—¶é•¿ > 0.5s?
           v
+--------------------------------+
| å¯åŠ¨æ–°çº¿ç¨‹ï¼Œå°† speech_buffer   |
| (æ‰“åŒ…æˆ speech_data)           |
| ä¼ é€’ç»™ ASR è¿›è¡Œè¯†åˆ«            |
+--------------------------------+

```

3. **å¯¹è¯å†å²ç¼“å†²åŒº** (`GPTClient.conversation_history`):
   - **ä½œç”¨**: å­˜å‚¨å¯¹è¯ä¸Šä¸‹æ–‡
   - **å¤§å°**: æœ€å¤š10è½®å¯¹è¯
   - **å¤„ç†**: è¶…å‡ºé•¿åº¦æ—¶è‡ªåŠ¨æˆªæ–­

### 3.3 çŠ¶æ€æœºè¯¦ç»†è¯´æ˜

#### çŠ¶æ€å®šä¹‰ï¼š
```python
class ConversationState(Enum):
    LISTENING = "listening"      # ç›‘å¬è¯­éŸ³è¾“å…¥
    RECOGNIZING = "recognizing"  # è¯­éŸ³è¯†åˆ«å¤„ç†ä¸­
    CHATTING = "chatting"       # GPTæ€è€ƒå›å¤ä¸­
    SPEAKING = "speaking"       # æ’­æ”¾AIå›å¤ä¸­(é¢„ç•™)
```

#### çŠ¶æ€è½¬æ¢é€»è¾‘ï¼š
```
LISTENING â†’ RECOGNIZING: VADæ£€æµ‹åˆ°å®Œæ•´è¯­éŸ³ç‰‡æ®µ
RECOGNIZING â†’ CHATTING: ASRè¯†åˆ«å®Œæˆï¼Œå¼€å§‹GPTå¤„ç†
CHATTING â†’ LISTENING: GPTå›å¤å®Œæˆï¼Œå›åˆ°ç›‘å¬çŠ¶æ€
```

#### çŠ¶æ€æœºä½œç”¨ï¼š
1. **é˜²æ­¢é‡å¤å¤„ç†**: åªåœ¨LISTENINGçŠ¶æ€å¤„ç†æ–°éŸ³é¢‘
2. **èµ„æºä¿æŠ¤**: é¿å…åŒæ—¶è¿›è¡Œå¤šä¸ªASR/GPTè°ƒç”¨
3. **æµç¨‹æ§åˆ¶**: ç¡®ä¿å¯¹è¯æµç¨‹çš„é¡ºåºæ‰§è¡Œ
4. **çŠ¶æ€ç›‘æ§**: æä¾›ç³»ç»Ÿå½“å‰çŠ¶æ€çš„å¯è§†åŒ–

#### VADçŠ¶æ€æœºï¼š
```python
# è¯­éŸ³æ£€æµ‹çŠ¶æ€æœº
if has_voice:
    speech_chunk_count += 1
    if speech_chunk_count >= min_speech_chunks:
        is_speaking = True  # è¯­éŸ³å¼€å§‹
else:
    silence_chunk_count += 1
    if silence_chunk_count >= max_silence_chunks:
        is_speaking = False  # è¯­éŸ³ç»“æŸ
```

## 4. VADå’ŒASRå‚æ•°è¯¦è§£

### 4.1 VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) å‚æ•°

#### æ ¸å¿ƒå‚æ•°ï¼š
```python
class SileroVAD:
    def __init__(self,
                 threshold: float = 0.02,      # è¯­éŸ³æ£€æµ‹é˜ˆå€¼
                 threshold_low: float = 0.005, # é™éŸ³æ£€æµ‹é˜ˆå€¼
                 frame_size: int = 512):       # åˆ†æå¸§å¤§å°
#æ¨¡å‹é…ç½® 
model_dir = "../models/snakers4_silero-vad"
```

#### å‚æ•°è¯´æ˜ï¼š
1. **`threshold` (è¯­éŸ³é˜ˆå€¼, é»˜è®¤0.1)**:
   - **ä½œç”¨**: VADæ¨¡å‹è¾“å‡ºæ¦‚ç‡è¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯è¯­éŸ³
   - **è°ƒä¼˜**:
     - è°ƒé«˜: å‡å°‘è¯¯æ£€ï¼Œä½†å¯èƒ½æ¼æ‰è½»å£°è¯´è¯
     - è°ƒä½: æ›´æ•æ„Ÿï¼Œä½†å¯èƒ½è¯¯æ£€ç¯å¢ƒå™ªéŸ³
 

2. **`threshold_low` (é™éŸ³é˜ˆå€¼, é»˜è®¤0.005)**:
   - **ä½œç”¨**: VADæ¦‚ç‡ä½äºæ­¤å€¼è®¤ä¸ºæ˜¯é™éŸ³
   - **è°ƒä¼˜**: é€šå¸¸è®¾ä¸ºthresholdçš„1/4åˆ°1/2
   - **ä½œç”¨**: é˜²æ­¢åœ¨thresholdé™„è¿‘é¢‘ç¹åˆ‡æ¢çŠ¶æ€

3. **`frame_size` (å¸§å¤§å°, å›ºå®š512)**:
   - **ä½œç”¨**: æ¯æ¬¡VADåˆ†æçš„éŸ³é¢‘æ ·æœ¬æ•°
   - **æ—¶é•¿**: 512æ ·æœ¬ = 32ms @ 16kHz
   - **æ³¨æ„**: ä¸å»ºè®®ä¿®æ”¹ï¼ŒSilero VADæ¨¡å‹é’ˆå¯¹æ­¤å¸§å¤§å°ä¼˜åŒ–

#### VADçŠ¶æ€æœºå‚æ•°ï¼š
```python
class AgoraConversationSystem:
    min_speech_chunks = 7      # æœ€å°è¿ç»­è¯­éŸ³å—æ•°
    max_silence_chunks = 15    # æœ€å¤§è¿ç»­é™éŸ³å—æ•°
```

4. **`min_speech_chunks` (æœ€å°è¯­éŸ³å—, é»˜è®¤7)**:
   - **ä½œç”¨**: è¿ç»­æ£€æµ‹åˆ°Nå—è¯­éŸ³æ‰è®¤ä¸ºè¯­éŸ³å¼€å§‹
   - **è°ƒä¼˜**:
     - å¢åŠ : å‡å°‘è¯¯è§¦å‘ï¼Œä½†å¢åŠ å“åº”å»¶è¿Ÿ
     - å‡å°‘: æ›´å¿«å“åº”ï¼Œä½†å¯èƒ½è¯¯è§¦å‘
   - **å»¶è¿Ÿ**: æ¯å—32msï¼Œ1å—=32mså»¶è¿Ÿ

5. **`max_silence_chunks` (æœ€å¤§é™éŸ³å—, é»˜è®¤15)**:
   - **ä½œç”¨**: è¿ç»­æ£€æµ‹åˆ°Nå—é™éŸ³æ‰è®¤ä¸ºè¯­éŸ³ç»“æŸ
   - **è°ƒä¼˜**:
     - å¢åŠ : å…è®¸æ›´é•¿çš„åœé¡¿ï¼Œé€‚åˆæ€è€ƒå‹å¯¹è¯
     - å‡å°‘: æ›´å¿«ç»“æŸæ£€æµ‹ï¼Œé€‚åˆå¿«é€Ÿå¯¹è¯
   - **æ—¶é•¿**: 10å— = 480msé™éŸ³åç»“æŸ

### 4.2 ASR (è¯­éŸ³è¯†åˆ«) å‚æ•°

#### æ ¸å¿ƒå‚æ•°ï¼š
1.  **æ¨¡å‹é…ç½®**:
    -   `model_dir = "../models/sherpa-onnx-whisper-base.en"`
    -   æ¨¡å‹æ–‡ä»¶éœ€è¦å¤åˆ¶åˆ° `yuv_pcm/models` ç›®å½•ä¸‹æ‰èƒ½ä½¿ç”¨ã€‚

2.  **æœ€å°è¯­éŸ³æ—¶é•¿è¿‡æ»¤**:
    -   è¿™æ˜¯ä¸€ä¸ªç¡¬ç¼–ç åœ¨ä»£ç ä¸­çš„å€¼ï¼Œç”¨äºè¿‡æ»¤æ‰æ— æ„ä¹‰çš„çŸ­æ—¶å™ªéŸ³ï¼ˆå¦‚å’³å—½ã€æ¸…å—“å­ç­‰ï¼‰ã€‚
    -   å½“å‰å€¼ä¸º **0.5ç§’**ã€‚

#### å‚æ•°è¯´æ˜ï¼š
1. **æœ€å°è¯­éŸ³æ—¶é•¿ (ç¡¬ç¼–ç å€¼, å½“å‰ 0.5ç§’)**:
   - **ä½œç”¨**: è¿‡æ»¤å¤ªçŸ­çš„è¯­éŸ³ç‰‡æ®µï¼Œé¿å…æ— æ•ˆè¯†åˆ«
   - **ä»£ç ä½ç½®**: `agora_vad_asr_gpt_system.py` çš„ `process_audio_chunk` å‡½æ•°ä¸­ã€‚
     ```python
     if len(self.speech_buffer) > self.sample_rate * 0.5:  # æœ€å°è¯­éŸ³æ—¶é•¿ï¼š0.5ç§’
         # ... å¼€å§‹è¯­éŸ³è¯†åˆ« ...
     ```
   - **è°ƒä¼˜**:
     - **è°ƒé«˜ (ä¾‹å¦‚ `* 0.8`)**: å¯ä»¥è¿‡æ»¤æ‰æ›´å¤šç±»ä¼¼å’³å—½çš„çŸ­ä¿ƒå™ªéŸ³ï¼Œä½†å¯èƒ½ä¼šæ¼æ‰ç®€çŸ­çš„å›ç­”ï¼ˆå¦‚â€œå¥½çš„â€ï¼‰ã€‚
     - **è°ƒä½ (ä¾‹å¦‚ `* 0.2`)**: å¯ä»¥æ•æ‰åˆ°æ›´çŸ­çš„æŒ‡ä»¤ï¼Œä½†ä¼šå¢åŠ å› å™ªéŸ³è¯¯è§¦å‘ASRå’ŒGPTçš„é£é™©ã€‚


## 5. ç¼–è¯‘è¿è¡Œå’Œè°ƒè¯•

### 5.1 ç¼–è¯‘æ­¥éª¤
```bash
cd agora_rtc_sdk/example/yuv_pcm/build
cmake ..
make vad_asr_gpt_intergrated
cp ../agora_vad_asr_system.py ./
```

### 5.2 è¿è¡Œç¨‹åº
```bash
./vad_asr_gpt_intergrated --token pull_token(ç”¨main_push.pyç”Ÿæˆ) --channelId JS_TEST1 --userId 999 --remoteUserId 1 --vadThreshold 0.1 --vadThresholdLow 0.005
```

### 5.3 å…³é”®æ—¥å¿—è§£è¯»
```bash
# æ­£å¸¸å¯åŠ¨æ—¥å¿—
âœ… PyTorchå¯ç”¨
âœ… Sherpa-ONNXå¯ç”¨
âœ… OpenAIå¯ç”¨
ğŸ”§ åˆå§‹åŒ–Agoraå¯¹è¯ç³»ç»Ÿ...
âœ… Silero VADæ¨¡å‹åŠ è½½æˆåŠŸ
âœ… GPTå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ

# è¿è¡Œæ—¶æ—¥å¿—
ğŸ¤ å¼€å§‹ç›‘å¬è¯­éŸ³...                    # VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
ğŸ”‡ è¯­éŸ³ç»“æŸï¼Œæ—¶é•¿: 1.31s              # VADæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
ğŸ“ ç”¨æˆ·è¯´: Hello world (è¯†åˆ«è€—æ—¶: 0.68s)  # ASRè¯†åˆ«ç»“æœ
ğŸ¤– AIå›å¤: Hi there! (æ€è€ƒè€—æ—¶: 3.2s)     # GPTå›å¤ç»“æœ
ğŸ”„ çŠ¶æ€åˆ‡æ¢: listening â†’ recognizing      # çŠ¶æ€æœºåˆ‡æ¢
```

### 5.4 ç»Ÿè®¡ä¿¡æ¯ç›‘æ§
```json
{
  "total_chunks": 1000,        // æ€»å¤„ç†éŸ³é¢‘å—æ•°
  "voice_chunks": 300,         // æ£€æµ‹åˆ°è¯­éŸ³çš„å—æ•°
  "voice_ratio": 30.0,         // è¯­éŸ³æ¯”ä¾‹(%)
  "conversation_count": 5,     // å®Œæˆçš„å¯¹è¯è½®æ•°
  "current_state": "listening" // å½“å‰ç³»ç»ŸçŠ¶æ€
}
```

---
